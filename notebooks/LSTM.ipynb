{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0194e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Any, List, Dict, Tuple, Union\n",
    "import itertools\n",
    "import json\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import floating\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f37fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'lstm_grid_search_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf2ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATETIME_COLUMN = 'candle_date_time_kst'\n",
    "# TARGET_COLUMN = 'win_or_lose'\n",
    "\n",
    "# CHECKPOINT_PATH = '../model_checkpoints/simple_time_features'\n",
    "CHECKPOINT_PATH = '../model_checkpoints/lstm_IOTA'\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "  os.makedirs(CHECKPOINT_PATH)\n",
    "\n",
    "TRAIN_DATA_FILE_NAME = 'IOTA_1m_3000000_2025-01-14T23:04:51+09:00.parquet_20250114230451.parquet'\n",
    "# TEST_DATA_FILE_NAME = 'IOTA_1s_2000_2025-01-12T23:21:27+09:00.parquet_20250112232127.parquet'\n",
    "\n",
    "# Parameters\n",
    "# INPUT_LENGTH = 60  # Number of past time steps to use as input\n",
    "# OUTPUT_LENGTH = 12  # Number of future time steps to predict\n",
    "# BATCH_SIZE = 32\n",
    "# LEARNING_RATE = 5e-4\n",
    "# EPOCHS = 10\n",
    "\n",
    "SEQUENCE_LENGTH = 24 * 4 * 4\n",
    "PREDICTION_LENGTH = 24 * 4\n",
    "LABEL_LENGTH = 24 * 4\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "PATIENCE = 15  # Early stopping patience\n",
    "\n",
    "\n",
    "NUM_BATCHES_PER_EPOCH = 100\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 5e-4\n",
    "SCALING = 'std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4037efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270b8a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataUtils:\n",
    "  \n",
    "  default_path = os.path.join(Path(os.getcwd()).parent, 'data')\n",
    "  \n",
    "  @staticmethod\n",
    "  def load_parquet(file_name: str, file_dir: Optional[str] = None):\n",
    "    if not file_dir:\n",
    "        file_dir = DataUtils.default_path\n",
    "        \n",
    "    path = os.path.join(file_dir, file_name)\n",
    "\n",
    "    if not os.path.exists(path) or file_name.split('.')[-1] != 'parquet':\n",
    "        return\n",
    "\n",
    "    print(f'Loading parquet file from: {path}')\n",
    "\n",
    "    return pd.read_parquet(path)\n",
    "  \n",
    "  @staticmethod\n",
    "  def feature_engineering(df: Optional[pd.DataFrame], prediction_horizon) -> pd.DataFrame:\n",
    "    if df is None:\n",
    "      return pd.DataFrame()\n",
    "\n",
    "    df['return_1m'] = df['mid_price'].pct_change(1)\n",
    "    df['return_5m'] = df['mid_price'].pct_change(5)\n",
    "    df['return_10m'] = df['mid_price'].pct_change(10)\n",
    "\n",
    "    # 2. 이동평균 Feature\n",
    "    df['ma_5'] = df['mid_price'].rolling(window=5).mean()\n",
    "    df['ma_10'] = df['mid_price'].rolling(window=10).mean()\n",
    "    df['ma_30'] = df['mid_price'].rolling(window=30).mean()\n",
    "\n",
    "    # 3. 이동 표준편차 Feature (변동성)\n",
    "    df['std_5'] = df['mid_price'].rolling(window=5).std()\n",
    "    df['std_10'] = df['mid_price'].rolling(window=10).std()\n",
    "\n",
    "    # 4. 거래량 Feature\n",
    "    df['volume_change_1m'] = df['candle_acc_trade_volume'].pct_change(1)\n",
    "    df['volume_ma_5'] = df['candle_acc_trade_volume'].rolling(5).mean()\n",
    "    df['volume_ratio'] = df['candle_acc_trade_volume'] / (df['volume_ma_5'] + 1e-9)\n",
    "\n",
    "    # 5. 가격 구조 Feature\n",
    "    df['high_low_spread'] = df['high_price'] - df['low_price']\n",
    "    df['is_bullish'] = (df['mid_price'] > df['opening_price']).astype(int)\n",
    "    df['body_size'] = np.abs(df['opening_price'] - df['mid_price'])\n",
    "    df['body_to_range'] = df['body_size'] / (df['high_price'] - df['low_price'] + 1e-9)\n",
    "\n",
    "    # 6. 기술적 지표 Feature\n",
    "\n",
    "    # Relative Strength Index (RSI)\n",
    "    window_length = 14\n",
    "    delta = df['mid_price'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window_length).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window_length).mean()\n",
    "    RS = gain / (loss + 1e-9)\n",
    "    df['RSI'] = 100 - (100 / (1 + RS))\n",
    "\n",
    "    # MACD\n",
    "    ema12 = df['mid_price'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df['mid_price'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = ema12 - ema26\n",
    "    df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # 7. 시간 정보 Feature (timestamp 있어야 가능)\n",
    "    # 예: df['timestamp'] 가 datetime 타입이라고 가정\n",
    "    if 'timestamp' in df.columns:\n",
    "      df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "      df['hour'] = df['timestamp'].dt.hour\n",
    "      df['minute'] = df['timestamp'].dt.minute\n",
    "      df['dayofweek'] = df['timestamp'].dt.dayofweek\n",
    "\n",
    "    # 8. Target 생성 (10분 후 수익률)\n",
    "    # prediction_horizon = 10\n",
    "    df['target_return'] = (df['mid_price'].shift(-prediction_horizon) - df['mid_price']) / df['mid_price']\n",
    "\n",
    "    # 9. NaN 제거\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a10c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parquet file from: /Users/minjiwon/upbase-data-server/data/IOTA_1m_3000000_2025-01-14T23:04:51+09:00.parquet_20250114230451.parquet\n"
     ]
    }
   ],
   "source": [
    "data = DataUtils.load_parquet(TRAIN_DATA_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2739e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'worst_profit_rate_before',\n",
    "    'opening_price', 'high_price', 'low_price', 'mid_price',\n",
    "    'candle_acc_trade_volume',\n",
    "    'return_1m', 'return_5m', 'return_10m',\n",
    "    'ma_5', 'ma_10', 'ma_30',\n",
    "    'std_5', 'std_10',\n",
    "    'volume_change_1m'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc3ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout=0.0):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers,\n",
    "            dropout=0.0 if hidden_dim == 1 else dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # 마지막 시점 hidden state만 사용 -> (batch_size, 1, input_dim)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class ScheduledSamplingLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_seq, target_seq=None, teacher_forcing_ratio=1.0):\n",
    "        \"\"\"\n",
    "        input_seq: (batch_size, window_size, input_dim)\n",
    "        target_seq: (batch_size, horizon, input_dim) — horizon-step future\n",
    "        \"\"\"\n",
    "        \n",
    "        if target_seq is None or teacher_forcing_ratio == 0.0:\n",
    "            out, _ = self.lstm(input_seq)\n",
    "            out = out[:, -1, :]  # 마지막 시점 hidden state만 사용\n",
    "            out = self.fc(out)\n",
    "            return out\n",
    "            \n",
    "\n",
    "        # teacher forcing\n",
    "        outputs = []\n",
    "        \n",
    "        _, (hidden, cell) = self.lstm(input_seq)\n",
    "        input_t = input_seq[:, -1:, :]  # shape: (batch, 1, input_dim)\n",
    "        horizon = target_seq.size(1)\n",
    "        \n",
    "        for t in range(horizon):\n",
    "            output, (hidden, cell) = self.lstm(input_t, (hidden, cell))\n",
    "            pred = self.fc(output)  # (batch, 1, output_dim)\n",
    "            outputs.append(pred)\n",
    "\n",
    "            # Scheduled Sampling\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                input_t = target_seq[:, t:t+1]\n",
    "            else:\n",
    "                input_t = pred.detach()  # 모델 예측 사용 (detach 해야 그래디언트 끊김)\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)  # (batch_size, horizon, output_dim)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b7eab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "FloatType = floating[Any]\n",
    "\n",
    "@dataclass\n",
    "class GridSearchResult:\n",
    "    \n",
    "    lr: float\n",
    "    hidden_dim: int\n",
    "    num_layers: int\n",
    "    output_dim: int\n",
    "    window_size: int\n",
    "    horizon: int\n",
    "    scheduled_sampling: bool\n",
    "    best_model: str\n",
    "    valid_loss: FloatType\n",
    "    test_loss: FloatType\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"lr={self.lr}, hidden_dim={self.hidden_dim}, num_layers={self.num_layers}, output_dim={self.output_dim}, window_size={self.window_size}, horizon={self.horizon}, valid_loss={self.valid_loss}, test_loss={self.test_loss}, best_model={self.best_model}, scheduled_sampling={self.scheduled_sampling}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"GridSearchResult(lr={self.lr}, hidden_dim={self.hidden_dim}, num_layers={self.num_layers}, output_dim={self.output_dim}, window_size={self.window_size}, horizon={self.horizon}, valid_loss={self.valid_loss}, test_loss={self.test_loss}, best_model={self.best_model}), scheduled_sampling={self.scheduled_sampling}\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, GridSearchResult):\n",
    "            return NotImplemented\n",
    "        \n",
    "        return (\n",
    "            self.lr == other.lr and\n",
    "            self.hidden_dim == other.hidden_dim and\n",
    "            self.num_layers == other.num_layers and\n",
    "            self.output_dim == other.output_dim and\n",
    "            self.window_size == other.window_size and\n",
    "            self.horizon == other.horizon and\n",
    "            self.valid_loss == other.valid_loss and\n",
    "            self.test_loss == other.test_loss and\n",
    "            self.best_model == other.best_model and\n",
    "            self.scheduled_sampling == other.scheduled_sampling\n",
    "        )\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Cell:\n",
    "    \n",
    "    lr: float\n",
    "    hidden_dim: int\n",
    "    num_layers: int\n",
    "    output_dim: int\n",
    "    dropout_rate: float\n",
    "    window_size: int\n",
    "    horizon: int\n",
    "    scheduled_sampling: bool\n",
    "    train_ratio: float = 0.7\n",
    "    valid_ratio: float = 0.15\n",
    "    test_ratio: float = 0.15\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"lr={self.lr}, hidden_dim={self.hidden_dim}, num_layers={self.num_layers}, output_dim={self.output_dim}, dropout_rate={self.dropout_rate}, window_size={self.window_size}, horizon={self.horizon}, scheduled_sampling={self.scheduled_sampling}, train_ratio={self.train_ratio}, valid_ratio={self.valid_ratio}, test_ratio={self.test_ratio}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Cell(lr={self.lr}, hidden_dim={self.hidden_dim}, num_layers={self.num_layers}, output_dim={self.output_dim}, dropout_rate={self.dropout_rate}, window_size={self.window_size}, horizon={self.horizon}), scheduled_sampling={self.scheduled_sampling}, train_ratio={self.train_ratio}, valid_ratio={self.valid_ratio}, test_ratio={self.test_ratio}\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Cell):\n",
    "            return NotImplemented   \n",
    "        \n",
    "        return (\n",
    "            self.lr == other.lr and\n",
    "            self.hidden_dim == other.hidden_dim and\n",
    "            self.num_layers == other.num_layers and\n",
    "            self.output_dim == other.output_dim and\n",
    "            self.dropout_rate == other.dropout_rate and\n",
    "            self.window_size == other.window_size and\n",
    "            self.horizon == other.horizon\n",
    "        )\n",
    "    \n",
    "    def shorthand(self):\n",
    "        return f\"{self.lr}_{self.hidden_dim}_{self.num_layers}_{self.output_dim}_{self.dropout_rate}_{self.window_size}_{self.horizon}_{self.scheduled_sampling}\"\n",
    "\n",
    "@dataclass \n",
    "class Grid:\n",
    "    \n",
    "    lr: List[float]\n",
    "    hidden_dim: List[int]\n",
    "    num_layers: List[int]\n",
    "    output_dim: List[int]\n",
    "    dropout_rate: List[float]\n",
    "    window_size: List[int]\n",
    "    horizon: List[int]\n",
    "    scheduled_sampling: List[bool]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"lr={self.lr}, hidden_dim={self.hidden_dim}, num_layers={self.num_layers}, output_dim={self.output_dim}, dropout_rate={self.dropout_rate}, window_size={self.window_size}, horizon={self.horizon}, scheduled_sampling={self.scheduled_sampling}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Grid(lr={self.lr}, hidden_dim={self.hidden_dim}, num_layers={self.num_layers}, output_dim={self.output_dim}, dropout_rate={self.dropout_rate}, window_size={self.window_size}, horizon={self.horizon}, scheduled_sampling={self.scheduled_sampling})\"\n",
    "    \n",
    "    def __eq__(self, other) :\n",
    "        if not isinstance(other, Grid):\n",
    "            return NotImplemented\n",
    "        \n",
    "        return (\n",
    "            self.lr == other.lr and\n",
    "            self.hidden_dim == other.hidden_dim and\n",
    "            self.num_layers == other.num_layers and\n",
    "            self.output_dim == other.output_dim and\n",
    "            self.dropout_rate == other.dropout_rate and\n",
    "            self.window_size == other.window_size and\n",
    "            self.horizon == other.horizon and \n",
    "            self.scheduled_sampling == other.scheduled_sampling\n",
    "        )\n",
    "        \n",
    "    def includes(self, other):\n",
    "        if isinstance(other, Cell):\n",
    "            return (\n",
    "                other.lr in set(self.lr) and\n",
    "                other.hidden_dim in set(self.hidden_dim) and\n",
    "                other.num_layers in set(self.num_layers) and\n",
    "                other.output_dim in set(self.output_dim) and\n",
    "                other.dropout_rate in set(self.dropout_rate) and\n",
    "                other.window_size in set(self.window_size) and\n",
    "                other.horizon in set(self.horizon) and \n",
    "                other.scheduled_sampling in set(self.scheduled_sampling)\n",
    "            )\n",
    "            \n",
    "        if isinstance(other, Grid):\n",
    "            return (\n",
    "                set(self.lr).issuperset(other.lr) and\n",
    "                set(self.hidden_dim).issuperset(other.hidden_dim) and\n",
    "                set(self.num_layers).issuperset(other.num_layers) and\n",
    "                set(self.output_dim).issuperset(other.output_dim) and\n",
    "                set(self.dropout_rate).issuperset(other.dropout_rate) and\n",
    "                set(self.window_size).issuperset(other.window_size) and\n",
    "                set(self.horizon).issuperset(other.horizon) and\n",
    "                set(self.scheduled_sampling).issuperset(other.scheduled_sampling)\n",
    "            )\n",
    "            \n",
    "        return NotImplemented\n",
    "        \n",
    "    def to_cells(self):\n",
    "        return [\n",
    "            Cell(\n",
    "                lr=lr,\n",
    "                hidden_dim=hidden_dim,\n",
    "                num_layers=num_layers,\n",
    "                output_dim=output_dim,\n",
    "                dropout_rate=dropout_rate,\n",
    "                window_size=window_size,\n",
    "                horizon=horizon,\n",
    "                scheduled_sampling=scheduled_sampling,\n",
    "            )\n",
    "            for (lr, hidden_dim, num_layers, output_dim, dropout_rate, window_size, horizon, scheduled_sampling) \n",
    "            in (itertools.product(\n",
    "                self.lr,\n",
    "                self.hidden_dim,\n",
    "                self.num_layers,\n",
    "                self.output_dim,\n",
    "                self.dropout_rate,\n",
    "                self.window_size,\n",
    "                self.horizon,\n",
    "                self.scheduled_sampling,\n",
    "            ))\n",
    "        ]\n",
    "        \n",
    "\n",
    "class Tester:\n",
    "    \n",
    "    @staticmethod\n",
    "    def test(params: Cell):\n",
    "        print(\"Making dataset...\", end='\\r', flush=True)\n",
    "        # 기본 세팅\n",
    "        # window_size = 60  # 과거 60개 (60분) 시점 사용\n",
    "        # horizon = 10      # 10분 후 수익률 예측\n",
    "        \n",
    "        data_pp = DataUtils.feature_engineering(data, prediction_horizon=params.horizon)\n",
    "        \n",
    "\n",
    "        # feature/target 준비\n",
    "        feature_cols = features  # 아까 정리한 feature 리스트\n",
    "        target_col = 'target_return'\n",
    "\n",
    "        num_data = int(len(data_pp) * 0.1)\n",
    "        data_pppp = data_pp.iloc[-num_data:]\n",
    "\n",
    "        X_all = data_pppp[feature_cols].values\n",
    "        y_all = data_pppp[target_col].values\n",
    "\n",
    "        # 시퀀스 데이터 만들기\n",
    "        X_seq = []\n",
    "        y_seq = []\n",
    "\n",
    "        for i in range(params.window_size, len(data_pppp) - params.horizon):\n",
    "            X_seq.append(X_all[i - params.window_size:i])\n",
    "            y_seq.append(y_all[i + params.horizon])\n",
    "\n",
    "        X_seq = np.array(X_seq)\n",
    "        y_seq = np.array(y_seq)\n",
    "\n",
    "        # print(f'data shape: {X_seq.shape}, {y_seq.shape}')  # (samples, time_steps, feature_dim), (samples,)\n",
    "\n",
    "        # train_ratio = 0.7\n",
    "        # valid_ratio = 0.15\n",
    "        # test_ratio = 0.15\n",
    "\n",
    "        n_total = len(X_seq)\n",
    "        n_train = int(n_total * params.train_ratio)\n",
    "        n_valid = int(n_total * params.valid_ratio)\n",
    "\n",
    "        X_train, y_train = X_seq[:n_train], y_seq[:n_train]\n",
    "        X_valid, y_valid = X_seq[n_train:n_train+n_valid], y_seq[n_train:n_train+n_valid]\n",
    "        X_test, y_test = X_seq[n_train+n_valid:], y_seq[n_train+n_valid:]\n",
    "\n",
    "        # print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "        \n",
    "        print(\"Preparing dataloaders...\", end='\\r', flush=True)\n",
    "        \n",
    "\n",
    "        # 1. Tensor 변환\n",
    "        device = DEVICE\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "        X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32).to(device)\n",
    "        y_valid_tensor = torch.tensor(y_valid, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "        # 2. DataLoader 만들기\n",
    "        # todo: batch_size 조정\n",
    "        batch_size = BATCH_SIZE\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # 모델 세팅\n",
    "        input_dim = X_train.shape[2]   # feature 수\n",
    "        # hidden_dim = 64\n",
    "        # num_layers = 2\n",
    "        # output_dim = 1\n",
    "        \n",
    "        # 3. 모델, Loss, Optimizer 세팅\n",
    "        model = (ScheduledSamplingLSTM if params.scheduled_sampling else LSTMModel)(\n",
    "            input_dim, \n",
    "            params.hidden_dim, \n",
    "            params.num_layers, \n",
    "            params.output_dim\n",
    "        ).to(device)\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params.lr, weight_decay=0)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "        # 4. 학습 루프\n",
    "        num_epochs = 100\n",
    "        best_valid_loss = np.inf\n",
    "        patience_counter = 0\n",
    "        \n",
    "        best_checkpoint: str = ''\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            \n",
    "            teacher_forcing_ratio = max(0.0, 1.0 - 0.05 * epoch) if params.scheduled_sampling else 0.0\n",
    "            \n",
    "            for index, (X_batch, y_batch) in enumerate(train_loader):\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} | ({(index + 1) / len(train_loader) * 100:.02f}% trained) - Train Loss: {np.mean(train_losses) if train_losses else np.inf:.6f}, lr: {scheduler.get_last_lr()}, teacher_forcing: {teacher_forcing_ratio}{' ' * 5}\", end='\\r', flush=True)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch, y_batch, teacher_forcing_ratio) if teacher_forcing_ratio > 0.0 else model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "            \n",
    "            # 검증\n",
    "            model.eval()\n",
    "            valid_losses = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for index, (X_batch, y_batch) in enumerate(valid_loader):\n",
    "                    print(f\"Epoch {epoch+1}/{num_epochs} | ({(index + 1) / len(valid_loader) * 100:.02f}% validated) - Valid Loss: {np.mean(valid_losses if valid_losses else np.inf):.6f}\", end='\\r', flush=True)\n",
    "                    \n",
    "                    outputs = model(X_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    valid_losses.append(loss.item())\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {np.mean(train_losses):.6f}, Valid Loss: {np.mean(valid_losses):.6f}\", end='\\r', flush=True)\n",
    "            \n",
    "            # avg_train_loss = np.mean(train_losses)\n",
    "            avg_valid_loss = np.mean(valid_losses)\n",
    "            scheduler.step(avg_valid_loss)\n",
    "            \n",
    "            # Early Stopping & Best Checkpoint 저장\n",
    "            if avg_valid_loss < best_valid_loss:\n",
    "                best_valid_loss = avg_valid_loss\n",
    "                best_checkpoint = os.path.join(CHECKPOINT_PATH, f'{EXPERIMENT_NAME}__{params.shorthand()}__{avg_valid_loss * 10000:.2f}.pth')\n",
    "                torch.save(model.state_dict(), best_checkpoint)\n",
    "                print(f\"✅ Best model saved at epoch {epoch + 1} with Valid Loss {best_valid_loss:.6f}, lr={scheduler.get_last_lr()}{' ' * 30}\", flush=True)\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= PATIENCE:\n",
    "                    print(f\"⏹️ Early stopping triggered at epoch {epoch + 1}{' ' * 80}\", flush=True)\n",
    "                    break\n",
    "                \n",
    "        model.load_state_dict(torch.load(best_checkpoint))\n",
    "        model.eval()\n",
    "\n",
    "        # Test 데이터로 최종 평가\n",
    "        test_losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for index, (X_batch, y_batch) in enumerate(test_loader):\n",
    "                print(f\"{(index + 1) / len(test_loader) * 100:.02f}% testing\", end='\\r', flush=True)\n",
    "                \n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "        avg_test_loss = np.mean(test_losses)\n",
    "        print(f'✅ Best Model 기준 최종 Test Loss (MSE): {avg_test_loss:.6f}{\" \" * 50}', flush=True)\n",
    "        \n",
    "        return GridSearchResult(\n",
    "            lr=params.lr,\n",
    "            hidden_dim=params.hidden_dim,\n",
    "            num_layers=params.num_layers,\n",
    "            output_dim=params.output_dim,\n",
    "            window_size=params.window_size,\n",
    "            horizon=params.horizon,\n",
    "            scheduled_sampling=params.scheduled_sampling,\n",
    "            best_model=best_checkpoint,\n",
    "            valid_loss=best_valid_loss,\n",
    "            test_loss=avg_test_loss,\n",
    "        )\n",
    "\n",
    "\n",
    "class GridSearch:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: Union[float, List[float]],\n",
    "        hidden_dim: Union[int, List[int]],\n",
    "        num_layers: Union[int, List[int]],\n",
    "        output_dim: Union[int, List[int]],\n",
    "        window_size: Union[int, List[int]],\n",
    "        horizon: Union[int, List[int]],\n",
    "        dropout_rate: Union[float, List[float]],\n",
    "        scheduled_sampling: Union[bool, List[bool]],\n",
    "        exceptions: Optional[Union[Grid, List[Cell]]] = None,\n",
    "    ):\n",
    "        self.grid = GridSearch.make_grid(\n",
    "            lr=lr,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            output_dim=output_dim,\n",
    "            window_size=window_size,\n",
    "            horizon=horizon,\n",
    "            dropout_rate=dropout_rate,\n",
    "            scheduled_sampling=scheduled_sampling,\n",
    "        )\n",
    "        self.exceptions = exceptions\n",
    "        self.results = []\n",
    "        \n",
    "    @staticmethod\n",
    "    def make_grid(\n",
    "        lr,\n",
    "        hidden_dim,\n",
    "        num_layers,\n",
    "        output_dim,\n",
    "        dropout_rate,\n",
    "        window_size,\n",
    "        horizon,\n",
    "        scheduled_sampling,\n",
    "    ):\n",
    "        return Grid(\n",
    "            lr=lr if isinstance(lr, list) else [lr],\n",
    "            hidden_dim=hidden_dim if isinstance(hidden_dim, list) else [hidden_dim],\n",
    "            num_layers=num_layers if isinstance(num_layers, list) else [num_layers],\n",
    "            output_dim=output_dim if isinstance(output_dim, list) else [output_dim],\n",
    "            dropout_rate=dropout_rate if isinstance(dropout_rate, list) else [dropout_rate],\n",
    "            window_size=window_size if isinstance(window_size, list) else [window_size],\n",
    "            horizon=horizon if isinstance(horizon, list) else [horizon],\n",
    "            scheduled_sampling=scheduled_sampling if isinstance(scheduled_sampling, list) else [scheduled_sampling],\n",
    "        )\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        def _is_exception(params):\n",
    "            if isinstance(self.exceptions, list):\n",
    "                return params in self.exceptions\n",
    "            elif isinstance(self.exceptions, Grid):\n",
    "                return self.exceptions.includes(params)\n",
    "            return False\n",
    "        \n",
    "        test_count = 0\n",
    "        \n",
    "        for params in self.grid.to_cells():\n",
    "            if params.window_size <= params.horizon:\n",
    "                print(f\"Skipping test with window_size={params.window_size} <= horizon={params.horizon}\", flush=True)\n",
    "                continue\n",
    "            \n",
    "            if _is_exception(params):\n",
    "                print(f\"Skipping test with params: {params} (in exceptions)\", flush=True)\n",
    "                continue\n",
    "            \n",
    "            test_count += 1\n",
    "            print(f\"[TEST #{test_count}]\\n{params}\")\n",
    "            \n",
    "            result = Tester.test(params)\n",
    "            \n",
    "            print(f\"Result: {result}\", end='\\n\\n\\n', flush=True)\n",
    "            self.results.append(result)\n",
    "                                \n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4475f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST #1]\n",
      "lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, dropout_rate=0.0, window_size=60, horizon=10, scheduled_sampling=False, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15\n",
      "✅ Best model saved at epoch 1 with Valid Loss 0.000057, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 4 with Valid Loss 0.000057, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 5 with Valid Loss 0.000056, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 6 with Valid Loss 0.000053, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 10 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 11 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 15 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 17 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 21 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 23 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "⏹️ Early stopping triggered at epoch 38                                                                                \n",
      "✅ Best Model 기준 최종 Test Loss (MSE): 0.000035                                                  \n",
      "Result: lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, window_size=60, horizon=10, valid_loss=5.108389388266203e-05, test_loss=3.476535859656487e-05, best_model=../model_checkpoints/lstm_IOTA/lstm_grid_search_2__0.0005_128_2_1_0.0_60_10_False__0.51.pth, scheduled_sampling=False\n",
      "\n",
      "\n",
      "[TEST #2]\n",
      "lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, dropout_rate=0.0, window_size=60, horizon=20, scheduled_sampling=False, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15\n",
      "✅ Best model saved at epoch 1 with Valid Loss 0.000115, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 2 with Valid Loss 0.000103, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 8 with Valid Loss 0.000103, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 9 with Valid Loss 0.000103, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 10 with Valid Loss 0.000102, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 11 with Valid Loss 0.000102, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 14 with Valid Loss 0.000102, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 15 with Valid Loss 0.000101, lr=[0.0005]                              \n",
      "⏹️ Early stopping triggered at epoch 30                                                                                \n",
      "✅ Best Model 기준 최종 Test Loss (MSE): 0.000071                                                  \n",
      "Result: lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, window_size=60, horizon=20, valid_loss=0.00010140232935305347, test_loss=7.074623241879008e-05, best_model=../model_checkpoints/lstm_IOTA/lstm_grid_search_2__0.0005_128_2_1_0.0_60_20_False__1.01.pth, scheduled_sampling=False\n",
      "\n",
      "\n",
      "[TEST #3]\n",
      "lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, dropout_rate=0.1, window_size=60, horizon=10, scheduled_sampling=False, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15\n",
      "✅ Best model saved at epoch 1 with Valid Loss 0.000057, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 3 with Valid Loss 0.000055, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 4 with Valid Loss 0.000053, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 7 with Valid Loss 0.000052, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 14 with Valid Loss 0.000052, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 17 with Valid Loss 0.000052, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 18 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 19 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 20 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 34 with Valid Loss 0.000051, lr=[5e-05]                              \n",
      "✅ Best model saved at epoch 41 with Valid Loss 0.000051, lr=[5e-05]                              \n",
      "✅ Best model saved at epoch 45 with Valid Loss 0.000051, lr=[5e-05]                              \n",
      "✅ Best model saved at epoch 48 with Valid Loss 0.000051, lr=[5e-05]                              \n",
      "⏹️ Early stopping triggered at epoch 63                                                                                \n",
      "✅ Best Model 기준 최종 Test Loss (MSE): 0.000035                                                  \n",
      "Result: lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, window_size=60, horizon=10, valid_loss=5.10733715049157e-05, test_loss=3.4859697668672325e-05, best_model=../model_checkpoints/lstm_IOTA/lstm_grid_search_2__0.0005_128_2_1_0.1_60_10_False__0.51.pth, scheduled_sampling=False\n",
      "\n",
      "\n",
      "[TEST #4]\n",
      "lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, dropout_rate=0.1, window_size=60, horizon=20, scheduled_sampling=False, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15\n",
      "✅ Best model saved at epoch 1 with Valid Loss 0.000118, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 4 with Valid Loss 0.000105, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 6 with Valid Loss 0.000104, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 11 with Valid Loss 0.000103, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 14 with Valid Loss 0.000102, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 16 with Valid Loss 0.000102, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 20 with Valid Loss 0.000101, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 28 with Valid Loss 0.000101, lr=[0.0005]                              \n",
      "⏹️ Early stopping triggered at epoch 43                                                                                \n",
      "✅ Best Model 기준 최종 Test Loss (MSE): 0.000071                                                  \n",
      "Result: lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, window_size=60, horizon=20, valid_loss=0.00010138421202774164, test_loss=7.067153047504585e-05, best_model=../model_checkpoints/lstm_IOTA/lstm_grid_search_2__0.0005_128_2_1_0.1_60_20_False__1.01.pth, scheduled_sampling=False\n",
      "\n",
      "\n",
      "[TEST #5]\n",
      "lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, dropout_rate=0.2, window_size=60, horizon=10, scheduled_sampling=False, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15\n",
      "✅ Best model saved at epoch 1 with Valid Loss 0.000057, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 3 with Valid Loss 0.000054, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 6 with Valid Loss 0.000052, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 8 with Valid Loss 0.000052, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 9 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 12 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 15 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 21 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 25 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 27 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 28 with Valid Loss 0.000051, lr=[0.0005]                              \n",
      "⏹️ Early stopping triggered at epoch 43                                                                                \n",
      "✅ Best Model 기준 최종 Test Loss (MSE): 0.000035                                                  \n",
      "Result: lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, window_size=60, horizon=10, valid_loss=5.1084889560233506e-05, test_loss=3.480001853251093e-05, best_model=../model_checkpoints/lstm_IOTA/lstm_grid_search_2__0.0005_128_2_1_0.2_60_10_False__0.51.pth, scheduled_sampling=False\n",
      "\n",
      "\n",
      "[TEST #6]\n",
      "lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, dropout_rate=0.2, window_size=60, horizon=20, scheduled_sampling=False, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15\n",
      "✅ Best model saved at epoch 1 with Valid Loss 0.000108, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 3 with Valid Loss 0.000107, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 4 with Valid Loss 0.000102, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 6 with Valid Loss 0.000102, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 7 with Valid Loss 0.000101, lr=[0.0005]                              \n",
      "✅ Best model saved at epoch 18 with Valid Loss 0.000101, lr=[0.0005]                              \n",
      "Epoch 19/100 | (26.20% trained) - Train Loss: 0.000124, lr: [0.0005], teacher_forcing: 0.0     \r"
     ]
    }
   ],
   "source": [
    "# batch_size = 128, data_size = 10%\n",
    "\n",
    "searcher = GridSearch(\n",
    "  lr=[5e-4],\n",
    "  hidden_dim=[128, 256],\n",
    "  num_layers=[2, 3],\n",
    "  output_dim=[1],\n",
    "  window_size=[60],\n",
    "  horizon=[10, 20],\n",
    "  dropout_rate=[0.0, 0.1, 0.2, 0.3],\n",
    "  scheduled_sampling=[False],\n",
    "  # exceptions=Grid(\n",
    "  #   lr=[1e-3],\n",
    "  #   hidden_dim=[64],\n",
    "  #   num_layers=[2],\n",
    "  #   output_dim=[1],\n",
    "  #   window_size=[60],\n",
    "  #   horizon=[10],\n",
    "  # )\n",
    ")\n",
    "\n",
    "result = searcher.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e1360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed06d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST #1] \n",
      "with params: lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, dropout_rate=0.0, window_size=120, horizon=20\n",
      "Preparing dataloaders...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minjiwon/upbase-data-server/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/minjiwon/upbase-data-server/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at epoch 1 with Valid Loss 0.00010303\n",
      "✅ Best model saved at epoch 2 with Valid Loss 0.00009898\n",
      "✅ Best model saved at epoch 6 with Valid Loss 0.00009898\n",
      "✅ Best model saved at epoch 9 with Valid Loss 0.00009898\n",
      "⏹️ Early stopping triggered at epoch 29lid Loss: 0.000098\n",
      "✅ Best Model 기준 최종 Test Loss (MSE): 0.000043\n",
      "Result: lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, window_size=120, horizon=20, valid_loss=9.768993973602255e-05, test_loss=4.295517223141218e-05, best_model=../model_checkpoints/lstm_IOTA/lstm_grid_search_2__0.0005_128_2_1_0.0_120_20_True__0.98.pth, scheduled_sampling=True\n",
      "\n",
      "\n",
      "[TEST #2] \n",
      "with params: lr=0.0005, hidden_dim=128, num_layers=2, output_dim=1, dropout_rate=0.1, window_size=120, horizon=20\n",
      "Preparing dataloaders...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minjiwon/upbase-data-server/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/minjiwon/upbase-data-server/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 | (46.35% trained) - Train Loss: 0.000058\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m searcher \u001b[38;5;241m=\u001b[39m GridSearch(\n\u001b[1;32m      2\u001b[0m   lr\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m5e-4\u001b[39m],\n\u001b[1;32m      3\u001b[0m   hidden_dim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 411\u001b[0m, in \u001b[0;36mGridSearch.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    408\u001b[0m test_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[TEST #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mwith params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 411\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mTester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[0;32mIn[61], line 273\u001b[0m, in \u001b[0;36mTester.test\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    271\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[1;32m    272\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[0;32m--> 273\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    275\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/upbase-data-server/.venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/upbase-data-server/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/upbase-data-server/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# batch_size = 128, data_size = 20%\n",
    "\n",
    "searcher = GridSearch(\n",
    "  lr=[5e-4],\n",
    "  hidden_dim=[128, 256],\n",
    "  num_layers=[2, 3],\n",
    "  output_dim=[1],\n",
    "  window_size=[60],\n",
    "  horizon=[10, 20],\n",
    "  dropout_rate=[0.1, 0.2, 0.3],\n",
    "  scheduled_sampling=[True, False],\n",
    "  # exceptions=Grid(\n",
    "  #   lr=[1e-3],\n",
    "  #   hidden_dim=[64],\n",
    "  #   num_layers=[2],\n",
    "  #   output_dim=[1],\n",
    "  #   window_size=[60],\n",
    "  #   horizon=[10],\n",
    "  # )\n",
    ")\n",
    "\n",
    "result = searcher.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44512de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./results/{EXPERIMENT_NAME}.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump([d.__dict__ for d in result], f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c5218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>output_dim</th>\n",
       "      <th>window_size</th>\n",
       "      <th>horizon</th>\n",
       "      <th>best_model</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>../model_checkpoints/lstm_IOTA/0.1__0.00.pth</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr  hidden_dim  num_layers  output_dim  window_size  horizon  \\\n",
       "9   0.0010         128           1           1           60       20   \n",
       "13  0.0010         128           2           1           60       20   \n",
       "28  0.0005         128           2           1           60       10   \n",
       "5   0.0010          64           2           1           60       20   \n",
       "20  0.0005          64           2           1           60       10   \n",
       "17  0.0005          64           1           1           60       20   \n",
       "12  0.0010         128           2           1           60       10   \n",
       "24  0.0005         128           1           1           60       10   \n",
       "4   0.0010          64           2           1           60       10   \n",
       "29  0.0005         128           2           1           60       20   \n",
       "19  0.0005          64           1           1          120       20   \n",
       "21  0.0005          64           2           1           60       20   \n",
       "7   0.0010          64           2           1          120       20   \n",
       "23  0.0005          64           2           1          120       20   \n",
       "8   0.0010         128           1           1           60       10   \n",
       "3   0.0010          64           1           1          120       20   \n",
       "15  0.0010         128           2           1          120       20   \n",
       "22  0.0005          64           2           1          120       10   \n",
       "6   0.0010          64           2           1          120       10   \n",
       "30  0.0005         128           2           1          120       10   \n",
       "14  0.0010         128           2           1          120       10   \n",
       "11  0.0010         128           1           1          120       20   \n",
       "18  0.0005          64           1           1          120       10   \n",
       "25  0.0005         128           1           1           60       20   \n",
       "31  0.0005         128           2           1          120       20   \n",
       "16  0.0005          64           1           1           60       10   \n",
       "10  0.0010         128           1           1          120       10   \n",
       "26  0.0005         128           1           1          120       10   \n",
       "27  0.0005         128           1           1          120       20   \n",
       "2   0.0010          64           1           1          120       10   \n",
       "0   0.0010          64           1           1           60       10   \n",
       "1   0.0010          64           1           1           60       20   \n",
       "\n",
       "                                      best_model  valid_loss  test_loss  \n",
       "9   ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "13  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "28  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "5   ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "20  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "17  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "12  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "24  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "4   ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "29  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "19  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "21  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "7   ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "23  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "8   ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "3   ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "15  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "22  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "6   ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "30  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "14  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "11  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "18  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "25  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "31  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "16  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "10  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "26  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "27  ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "2   ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "0   ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  \n",
       "1   ../model_checkpoints/lstm_IOTA/0.1__0.00.pth    0.000051   0.000035  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame([d.__dict__ for d in result])\n",
    "result_df = result_df.sort_values(by='test_loss', ascending=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./results/grid_search_1.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca76ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
